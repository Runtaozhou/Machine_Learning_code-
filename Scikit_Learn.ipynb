{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "iris =datasets.load_iris()\n",
    "X = iris.data[:100,[2,3]]\n",
    "y = iris.target[0:100]\n",
    "print('class labels:',np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [50 50]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1,stratify=y)\n",
    "print(\"Labels counts in y:\",np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in testing y: [12 13]\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels counts in testing y:\",np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in training y: [38 37]\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels counts in training y:\",np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(eta0=0.1, max_iter=100, n_iter_no_change=50, random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "ppn = Perceptron(max_iter=100, n_iter_no_change=50, eta0=0.1,random_state=1)\n",
    "ppn.fit(X_train_std,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_predict = ppn.predict(X_test_std)\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassified examples: 0\n"
     ]
    }
   ],
   "source": [
    "print('misclassified examples: %d' %(y_test!=y_predict).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I personally thinks that perceptron classifier works well only on binary classification tasks.\\nif we want to make multiclass classidications then we need to use DECISION TREE CLASSIFIER'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_new = iris.data[:,[2,3]]\n",
    "y_new = iris.target\n",
    "\n",
    "\"\"\"I personally thinks that perceptron classifier works well only on binary classification tasks.\n",
    "if we want to make multiclass classidications then we need to use DECISION TREE CLASSIFIER\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_train,X_new_test,y_new_train,y_new_test = train_test_split(X_new,y_new,random_state=1,stratify=y_new)\n",
    "sn = StandardScaler()\n",
    "X_new_train_std = sn.fit_transform(X_new_train)\n",
    "X_new_test_std = sn.fit_transform(X_new_test)\n",
    "dtree = DecisionTreeClassifier().fit(X_new_train_std,y_new_train)\n",
    "dpredictions = dtree.predict(X_new_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 0 0 1 0 1 1 0 1 2 2 2 1 2 1 2 1 1 1 1 2 2 1 0 0 0 1 2 0 0 2 1 0 0 1 2\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "print(dpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "misclassified examples: 1\n"
     ]
    }
   ],
   "source": [
    "print('misclassified examples: %d'  %(y_new_test!=dpredictions).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_new_test,dpredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 12]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is: 0.974\n"
     ]
    }
   ],
   "source": [
    "print('the accuracy is: %.3f' %accuracy_score(y_new_test,dpredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plot the decision region'''\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_decision_region(X,y,classifier,test_idx=None,resolution=0.02):\n",
    "    markers =('s','x','o','^','v')\n",
    "    colors = ('red','blue','green','yellow','purple')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y_new))])\n",
    "    x1_min,x1_max = X[:,0].min()-1,X[:,0].max()+1\n",
    "    x2_min,x2_max = X[:,1].min()-1,X[:,1].max()+1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min,x1_max,resolution),np.arange(x2_min,x2_max,resolution))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 0.01\n",
    "x1_min,x1_max = X[:,0].min()-1,X[:,0].max()+1\n",
    "x2_min,x2_max = X[:,1].min()-1,X[:,1].max()+1\n",
    "xx1, xx2 = np.meshgrid(np.arange(x1_min,x1_max,resolution),np.arange(x2_min,x2_max,resolution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 6.1 -0.9 2.8\n"
     ]
    }
   ],
   "source": [
    "print(x1_min,x1_max,x2_min,x2_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
      "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
      "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
      "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
      "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
      "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
      "       0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
      "       0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
      "       0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
      "       0.99, 1.  , 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09,\n",
      "       1.1 , 1.11, 1.12, 1.13, 1.14, 1.15, 1.16, 1.17, 1.18, 1.19, 1.2 ,\n",
      "       1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3 , 1.31,\n",
      "       1.32, 1.33, 1.34, 1.35, 1.36, 1.37, 1.38, 1.39, 1.4 , 1.41, 1.42,\n",
      "       1.43, 1.44, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5 , 1.51, 1.52, 1.53,\n",
      "       1.54, 1.55, 1.56, 1.57, 1.58, 1.59, 1.6 , 1.61, 1.62, 1.63, 1.64,\n",
      "       1.65, 1.66, 1.67, 1.68, 1.69, 1.7 , 1.71, 1.72, 1.73, 1.74, 1.75,\n",
      "       1.76, 1.77, 1.78, 1.79, 1.8 , 1.81, 1.82, 1.83, 1.84, 1.85, 1.86,\n",
      "       1.87, 1.88, 1.89, 1.9 , 1.91, 1.92, 1.93, 1.94, 1.95, 1.96, 1.97,\n",
      "       1.98, 1.99, 2.  , 2.01, 2.02, 2.03, 2.04, 2.05, 2.06, 2.07, 2.08,\n",
      "       2.09, 2.1 , 2.11, 2.12, 2.13, 2.14, 2.15, 2.16, 2.17, 2.18, 2.19,\n",
      "       2.2 , 2.21, 2.22, 2.23, 2.24, 2.25, 2.26, 2.27, 2.28, 2.29, 2.3 ,\n",
      "       2.31, 2.32, 2.33, 2.34, 2.35, 2.36, 2.37, 2.38, 2.39, 2.4 , 2.41,\n",
      "       2.42, 2.43, 2.44, 2.45, 2.46, 2.47, 2.48, 2.49, 2.5 , 2.51, 2.52,\n",
      "       2.53, 2.54, 2.55, 2.56, 2.57, 2.58, 2.59, 2.6 , 2.61, 2.62, 2.63,\n",
      "       2.64, 2.65, 2.66, 2.67, 2.68, 2.69, 2.7 , 2.71, 2.72, 2.73, 2.74,\n",
      "       2.75, 2.76, 2.77, 2.78, 2.79, 2.8 , 2.81, 2.82, 2.83, 2.84, 2.85,\n",
      "       2.86, 2.87, 2.88, 2.89, 2.9 , 2.91, 2.92, 2.93, 2.94, 2.95, 2.96,\n",
      "       2.97, 2.98, 2.99, 3.  , 3.01, 3.02, 3.03, 3.04, 3.05, 3.06, 3.07,\n",
      "       3.08, 3.09, 3.1 , 3.11, 3.12, 3.13, 3.14, 3.15, 3.16, 3.17, 3.18,\n",
      "       3.19, 3.2 , 3.21, 3.22, 3.23, 3.24, 3.25, 3.26, 3.27, 3.28, 3.29,\n",
      "       3.3 , 3.31, 3.32, 3.33, 3.34, 3.35, 3.36, 3.37, 3.38, 3.39, 3.4 ,\n",
      "       3.41, 3.42, 3.43, 3.44, 3.45, 3.46, 3.47, 3.48, 3.49, 3.5 , 3.51,\n",
      "       3.52, 3.53, 3.54, 3.55, 3.56, 3.57, 3.58, 3.59, 3.6 , 3.61, 3.62,\n",
      "       3.63, 3.64, 3.65, 3.66, 3.67, 3.68, 3.69, 3.7 , 3.71, 3.72, 3.73,\n",
      "       3.74, 3.75, 3.76, 3.77, 3.78, 3.79, 3.8 , 3.81, 3.82, 3.83, 3.84,\n",
      "       3.85, 3.86, 3.87, 3.88, 3.89, 3.9 , 3.91, 3.92, 3.93, 3.94, 3.95,\n",
      "       3.96, 3.97, 3.98, 3.99, 4.  , 4.01, 4.02, 4.03, 4.04, 4.05, 4.06,\n",
      "       4.07, 4.08, 4.09, 4.1 , 4.11, 4.12, 4.13, 4.14, 4.15, 4.16, 4.17,\n",
      "       4.18, 4.19, 4.2 , 4.21, 4.22, 4.23, 4.24, 4.25, 4.26, 4.27, 4.28,\n",
      "       4.29, 4.3 , 4.31, 4.32, 4.33, 4.34, 4.35, 4.36, 4.37, 4.38, 4.39,\n",
      "       4.4 , 4.41, 4.42, 4.43, 4.44, 4.45, 4.46, 4.47, 4.48, 4.49, 4.5 ,\n",
      "       4.51, 4.52, 4.53, 4.54, 4.55, 4.56, 4.57, 4.58, 4.59, 4.6 , 4.61,\n",
      "       4.62, 4.63, 4.64, 4.65, 4.66, 4.67, 4.68, 4.69, 4.7 , 4.71, 4.72,\n",
      "       4.73, 4.74, 4.75, 4.76, 4.77, 4.78, 4.79, 4.8 , 4.81, 4.82, 4.83,\n",
      "       4.84, 4.85, 4.86, 4.87, 4.88, 4.89, 4.9 , 4.91, 4.92, 4.93, 4.94,\n",
      "       4.95, 4.96, 4.97, 4.98, 4.99, 5.  , 5.01, 5.02, 5.03, 5.04, 5.05,\n",
      "       5.06, 5.07, 5.08, 5.09, 5.1 , 5.11, 5.12, 5.13, 5.14, 5.15, 5.16,\n",
      "       5.17, 5.18, 5.19, 5.2 , 5.21, 5.22, 5.23, 5.24, 5.25, 5.26, 5.27,\n",
      "       5.28, 5.29, 5.3 , 5.31, 5.32, 5.33, 5.34, 5.35, 5.36, 5.37, 5.38,\n",
      "       5.39, 5.4 , 5.41, 5.42, 5.43, 5.44, 5.45, 5.46, 5.47, 5.48, 5.49,\n",
      "       5.5 , 5.51, 5.52, 5.53, 5.54, 5.55, 5.56, 5.57, 5.58, 5.59, 5.6 ,\n",
      "       5.61, 5.62, 5.63, 5.64, 5.65, 5.66, 5.67, 5.68, 5.69, 5.7 , 5.71,\n",
      "       5.72, 5.73, 5.74, 5.75, 5.76, 5.77, 5.78, 5.79, 5.8 , 5.81, 5.82,\n",
      "       5.83, 5.84, 5.85, 5.86, 5.87, 5.88, 5.89, 5.9 , 5.91, 5.92, 5.93,\n",
      "       5.94, 5.95, 5.96, 5.97, 5.98, 5.99, 6.  , 6.01, 6.02, 6.03, 6.04,\n",
      "       6.05, 6.06, 6.07, 6.08, 6.09])]\n"
     ]
    }
   ],
   "source": [
    "xx1 = np.meshgrid(np.arange(x1_min,x1_max,resolution))\n",
    "print(xx1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx2 = np.meshgrid(np.arange(x2_min,x2_max,resolution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-9.00000000e-01, -8.90000000e-01, -8.80000000e-01, -8.70000000e-01,\n",
      "       -8.60000000e-01, -8.50000000e-01, -8.40000000e-01, -8.30000000e-01,\n",
      "       -8.20000000e-01, -8.10000000e-01, -8.00000000e-01, -7.90000000e-01,\n",
      "       -7.80000000e-01, -7.70000000e-01, -7.60000000e-01, -7.50000000e-01,\n",
      "       -7.40000000e-01, -7.30000000e-01, -7.20000000e-01, -7.10000000e-01,\n",
      "       -7.00000000e-01, -6.90000000e-01, -6.80000000e-01, -6.70000000e-01,\n",
      "       -6.60000000e-01, -6.50000000e-01, -6.40000000e-01, -6.30000000e-01,\n",
      "       -6.20000000e-01, -6.10000000e-01, -6.00000000e-01, -5.90000000e-01,\n",
      "       -5.80000000e-01, -5.70000000e-01, -5.60000000e-01, -5.50000000e-01,\n",
      "       -5.40000000e-01, -5.30000000e-01, -5.20000000e-01, -5.10000000e-01,\n",
      "       -5.00000000e-01, -4.90000000e-01, -4.80000000e-01, -4.70000000e-01,\n",
      "       -4.60000000e-01, -4.50000000e-01, -4.40000000e-01, -4.30000000e-01,\n",
      "       -4.20000000e-01, -4.10000000e-01, -4.00000000e-01, -3.90000000e-01,\n",
      "       -3.80000000e-01, -3.70000000e-01, -3.60000000e-01, -3.50000000e-01,\n",
      "       -3.40000000e-01, -3.30000000e-01, -3.20000000e-01, -3.10000000e-01,\n",
      "       -3.00000000e-01, -2.90000000e-01, -2.80000000e-01, -2.70000000e-01,\n",
      "       -2.60000000e-01, -2.50000000e-01, -2.40000000e-01, -2.30000000e-01,\n",
      "       -2.20000000e-01, -2.10000000e-01, -2.00000000e-01, -1.90000000e-01,\n",
      "       -1.80000000e-01, -1.70000000e-01, -1.60000000e-01, -1.50000000e-01,\n",
      "       -1.40000000e-01, -1.30000000e-01, -1.20000000e-01, -1.10000000e-01,\n",
      "       -1.00000000e-01, -9.00000000e-02, -8.00000000e-02, -7.00000000e-02,\n",
      "       -6.00000000e-02, -5.00000000e-02, -4.00000000e-02, -3.00000000e-02,\n",
      "       -2.00000000e-02, -1.00000000e-02,  7.77156117e-16,  1.00000000e-02,\n",
      "        2.00000000e-02,  3.00000000e-02,  4.00000000e-02,  5.00000000e-02,\n",
      "        6.00000000e-02,  7.00000000e-02,  8.00000000e-02,  9.00000000e-02,\n",
      "        1.00000000e-01,  1.10000000e-01,  1.20000000e-01,  1.30000000e-01,\n",
      "        1.40000000e-01,  1.50000000e-01,  1.60000000e-01,  1.70000000e-01,\n",
      "        1.80000000e-01,  1.90000000e-01,  2.00000000e-01,  2.10000000e-01,\n",
      "        2.20000000e-01,  2.30000000e-01,  2.40000000e-01,  2.50000000e-01,\n",
      "        2.60000000e-01,  2.70000000e-01,  2.80000000e-01,  2.90000000e-01,\n",
      "        3.00000000e-01,  3.10000000e-01,  3.20000000e-01,  3.30000000e-01,\n",
      "        3.40000000e-01,  3.50000000e-01,  3.60000000e-01,  3.70000000e-01,\n",
      "        3.80000000e-01,  3.90000000e-01,  4.00000000e-01,  4.10000000e-01,\n",
      "        4.20000000e-01,  4.30000000e-01,  4.40000000e-01,  4.50000000e-01,\n",
      "        4.60000000e-01,  4.70000000e-01,  4.80000000e-01,  4.90000000e-01,\n",
      "        5.00000000e-01,  5.10000000e-01,  5.20000000e-01,  5.30000000e-01,\n",
      "        5.40000000e-01,  5.50000000e-01,  5.60000000e-01,  5.70000000e-01,\n",
      "        5.80000000e-01,  5.90000000e-01,  6.00000000e-01,  6.10000000e-01,\n",
      "        6.20000000e-01,  6.30000000e-01,  6.40000000e-01,  6.50000000e-01,\n",
      "        6.60000000e-01,  6.70000000e-01,  6.80000000e-01,  6.90000000e-01,\n",
      "        7.00000000e-01,  7.10000000e-01,  7.20000000e-01,  7.30000000e-01,\n",
      "        7.40000000e-01,  7.50000000e-01,  7.60000000e-01,  7.70000000e-01,\n",
      "        7.80000000e-01,  7.90000000e-01,  8.00000000e-01,  8.10000000e-01,\n",
      "        8.20000000e-01,  8.30000000e-01,  8.40000000e-01,  8.50000000e-01,\n",
      "        8.60000000e-01,  8.70000000e-01,  8.80000000e-01,  8.90000000e-01,\n",
      "        9.00000000e-01,  9.10000000e-01,  9.20000000e-01,  9.30000000e-01,\n",
      "        9.40000000e-01,  9.50000000e-01,  9.60000000e-01,  9.70000000e-01,\n",
      "        9.80000000e-01,  9.90000000e-01,  1.00000000e+00,  1.01000000e+00,\n",
      "        1.02000000e+00,  1.03000000e+00,  1.04000000e+00,  1.05000000e+00,\n",
      "        1.06000000e+00,  1.07000000e+00,  1.08000000e+00,  1.09000000e+00,\n",
      "        1.10000000e+00,  1.11000000e+00,  1.12000000e+00,  1.13000000e+00,\n",
      "        1.14000000e+00,  1.15000000e+00,  1.16000000e+00,  1.17000000e+00,\n",
      "        1.18000000e+00,  1.19000000e+00,  1.20000000e+00,  1.21000000e+00,\n",
      "        1.22000000e+00,  1.23000000e+00,  1.24000000e+00,  1.25000000e+00,\n",
      "        1.26000000e+00,  1.27000000e+00,  1.28000000e+00,  1.29000000e+00,\n",
      "        1.30000000e+00,  1.31000000e+00,  1.32000000e+00,  1.33000000e+00,\n",
      "        1.34000000e+00,  1.35000000e+00,  1.36000000e+00,  1.37000000e+00,\n",
      "        1.38000000e+00,  1.39000000e+00,  1.40000000e+00,  1.41000000e+00,\n",
      "        1.42000000e+00,  1.43000000e+00,  1.44000000e+00,  1.45000000e+00,\n",
      "        1.46000000e+00,  1.47000000e+00,  1.48000000e+00,  1.49000000e+00,\n",
      "        1.50000000e+00,  1.51000000e+00,  1.52000000e+00,  1.53000000e+00,\n",
      "        1.54000000e+00,  1.55000000e+00,  1.56000000e+00,  1.57000000e+00,\n",
      "        1.58000000e+00,  1.59000000e+00,  1.60000000e+00,  1.61000000e+00,\n",
      "        1.62000000e+00,  1.63000000e+00,  1.64000000e+00,  1.65000000e+00,\n",
      "        1.66000000e+00,  1.67000000e+00,  1.68000000e+00,  1.69000000e+00,\n",
      "        1.70000000e+00,  1.71000000e+00,  1.72000000e+00,  1.73000000e+00,\n",
      "        1.74000000e+00,  1.75000000e+00,  1.76000000e+00,  1.77000000e+00,\n",
      "        1.78000000e+00,  1.79000000e+00,  1.80000000e+00,  1.81000000e+00,\n",
      "        1.82000000e+00,  1.83000000e+00,  1.84000000e+00,  1.85000000e+00,\n",
      "        1.86000000e+00,  1.87000000e+00,  1.88000000e+00,  1.89000000e+00,\n",
      "        1.90000000e+00,  1.91000000e+00,  1.92000000e+00,  1.93000000e+00,\n",
      "        1.94000000e+00,  1.95000000e+00,  1.96000000e+00,  1.97000000e+00,\n",
      "        1.98000000e+00,  1.99000000e+00,  2.00000000e+00,  2.01000000e+00,\n",
      "        2.02000000e+00,  2.03000000e+00,  2.04000000e+00,  2.05000000e+00,\n",
      "        2.06000000e+00,  2.07000000e+00,  2.08000000e+00,  2.09000000e+00,\n",
      "        2.10000000e+00,  2.11000000e+00,  2.12000000e+00,  2.13000000e+00,\n",
      "        2.14000000e+00,  2.15000000e+00,  2.16000000e+00,  2.17000000e+00,\n",
      "        2.18000000e+00,  2.19000000e+00,  2.20000000e+00,  2.21000000e+00,\n",
      "        2.22000000e+00,  2.23000000e+00,  2.24000000e+00,  2.25000000e+00,\n",
      "        2.26000000e+00,  2.27000000e+00,  2.28000000e+00,  2.29000000e+00,\n",
      "        2.30000000e+00,  2.31000000e+00,  2.32000000e+00,  2.33000000e+00,\n",
      "        2.34000000e+00,  2.35000000e+00,  2.36000000e+00,  2.37000000e+00,\n",
      "        2.38000000e+00,  2.39000000e+00,  2.40000000e+00,  2.41000000e+00,\n",
      "        2.42000000e+00,  2.43000000e+00,  2.44000000e+00,  2.45000000e+00,\n",
      "        2.46000000e+00,  2.47000000e+00,  2.48000000e+00,  2.49000000e+00,\n",
      "        2.50000000e+00,  2.51000000e+00,  2.52000000e+00,  2.53000000e+00,\n",
      "        2.54000000e+00,  2.55000000e+00,  2.56000000e+00,  2.57000000e+00,\n",
      "        2.58000000e+00,  2.59000000e+00,  2.60000000e+00,  2.61000000e+00,\n",
      "        2.62000000e+00,  2.63000000e+00,  2.64000000e+00,  2.65000000e+00,\n",
      "        2.66000000e+00,  2.67000000e+00,  2.68000000e+00,  2.69000000e+00,\n",
      "        2.70000000e+00,  2.71000000e+00,  2.72000000e+00,  2.73000000e+00,\n",
      "        2.74000000e+00,  2.75000000e+00,  2.76000000e+00,  2.77000000e+00,\n",
      "        2.78000000e+00,  2.79000000e+00])]\n"
     ]
    }
   ],
   "source": [
    "print(xx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
